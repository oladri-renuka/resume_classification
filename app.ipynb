{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d132f6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you need to install all these in your terminal\n",
    "# pip install streamlit\n",
    "# pip install scikit-learn\n",
    "# pip install python-docx\n",
    "# pip install PyPDF2\n",
    "\n",
    "\n",
    "import streamlit as st\n",
    "import pickle\n",
    "import PyPDF2  # Extract text from PDF\n",
    "import re\n",
    "\n",
    "# Load pre-trained model and TF-IDF vectorizer (ensure these are saved earlier)\n",
    "knn_model = pickle.load(open('knn_model.pkl', 'rb'))  # Example file name, adjust as needed\n",
    "tfidf = pickle.load(open('tfidf.pkl', 'rb'))  # Example file name, adjust as needed\n",
    "le = pickle.load(open('encoder.pkl', 'rb'))  # Example file name, adjust as needed\n",
    "\n",
    "\n",
    "# Function to clean resume text\n",
    "def clean_text(text):\n",
    "    # Remove RT and cc\n",
    "    text = re.sub(r'\\bRT\\b|cc', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    # Remove non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7f]', '', text)\n",
    "    # Remove punctuations and special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Strip leading and trailing whitespace\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(file):\n",
    "    pdf_reader = PyPDF2.PdfReader(file)\n",
    "    text = ''\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "\n",
    "# Function to extract text from TXT with explicit encoding handling\n",
    "def extract_text_from_txt(file):\n",
    "    # Try using utf-8 encoding for reading the text file\n",
    "    try:\n",
    "        text = file.read().decode('utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        # In case utf-8 fails, try 'latin-1' encoding as a fallback\n",
    "        text = file.read().decode('latin-1')\n",
    "    return text\n",
    "\n",
    "\n",
    "# Function to handle file upload and extraction\n",
    "def handle_file_upload(uploaded_file):\n",
    "    file_extension = uploaded_file.name.split('.')[-1].lower()\n",
    "    if file_extension == 'pdf':\n",
    "        text = extract_text_from_pdf(uploaded_file)\n",
    "    elif file_extension == 'txt':\n",
    "        text = extract_text_from_txt(uploaded_file)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type. Please upload a PDF, DOCX, or TXT file.\")\n",
    "    return text\n",
    "\n",
    "\n",
    "# Function to predict the category of a resume\n",
    "def pred(input_resume):\n",
    "    # Preprocess the input text (e.g., cleaning, etc.)\n",
    "    cleaned_text = clean_text(input_resume)\n",
    "\n",
    "    # Vectorize the cleaned text using the same TF-IDF vectorizer used during training\n",
    "    vectorized_text = tfidf.transform([cleaned_text])\n",
    "\n",
    "    # Convert sparse matrix to dense\n",
    "    vectorized_text = vectorized_text.toarray()\n",
    "\n",
    "    # Prediction\n",
    "    predicted_category = knn_model.predict(vectorized_text)\n",
    "\n",
    "    # get name of predicted category\n",
    "    predicted_category_name = le.inverse_transform(predicted_category)\n",
    "\n",
    "    return predicted_category_name[0]  # Return the category name\n",
    "\n",
    "\n",
    "# Streamlit app layout\n",
    "def main():\n",
    "    st.set_page_config(page_title=\"Resume Classification\", page_icon=\"ðŸ“„\", layout=\"wide\")\n",
    "\n",
    "    st.title(\"Resume Category Prediction App\")\n",
    "    st.markdown(\"Upload your resume in PDF, or TXT format and get the predicted job category.\")\n",
    "\n",
    "    # File upload section\n",
    "    uploaded_file = st.file_uploader(\"Upload a Resume\", type=[\"pdf\", \"txt\"])\n",
    "\n",
    "    if uploaded_file is not None:\n",
    "        # Extract text from the uploaded file\n",
    "        try:\n",
    "            resume_text = handle_file_upload(uploaded_file)\n",
    "            st.write(\"Successfully extracted the text from the uploaded resume.\")\n",
    "\n",
    "            # Display extracted text (optional)\n",
    "            if st.checkbox(\"Show extracted text\", False):\n",
    "                st.text_area(\"Extracted Resume Text\", resume_text, height=300)\n",
    "\n",
    "            # Make prediction\n",
    "            st.subheader(\"Predicted Category\")\n",
    "            category = pred(resume_text)\n",
    "            st.write(f\"The predicted category of the uploaded resume is: **{category}**\")\n",
    "\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error processing the file: {str(e)}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaca48d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
